There are numerous variants of the genetic algorithm. We attempt to make our implementation as generic as possible. Our implementation is based on the GA described in "Evolutionary algorithms in theory and practice". It is also very similar to the GA described in "Evolution in time and space", but we use tournament selection instead of proportional selection, and we use elitism.

## Generational model

The generational model is one the, if not the most, popular models. Simply put it generates $n$ offsprings from a population of size $n$ and replaces the population with the offsprings. The offsprings are generated by selecting $k$ individuals (usually 2) from the population and applying a crossover method to the selected individuals until the $n$ offsprings have been generated. The newly generated offsprings are then mutated before replacing the original population. Mutation is optional.

### Diagram

![generational](img/models/generational.png)

### Pseudocode

```
offsprings = ()
while size of offspring < size of population:
    parents = select(population, k)
    children = crossover(parents)
    add children to offsprings

for each individual of offsprings:
    if rand() < mutationRate:
        mutate(individual)

replace population with offsprings
```

### Operators

| Operator        | Presence |
|-----------------|----------|
| Selector        | Required |
| Crossover       | Required |
| Mutator         | Optional |
| Mutation rate   | Optional |


## Steady state model

This GA is steady state meaning that there are no generations. It differs from the generic GA in that tournament selection does not replace the selected individuals in the population, and instead of adding the children of the selected parents into the next generation, the two best individuals out of the two parents and two children are added back into the population so that the population size remains constant.

P <- generate a population of individuals randomly
while stopping criterion has not been met:
    parent1 <- tournament_selection(P)
    parent2 <- tournament_selection(P)
    child1, child2 <- with probability cross_rate crossover parent1, parent2
    child1 <- mutate child1
    child2 <- mutate child2
    best1, best2 <- get the two highest fitness individuals out of parent1, parent2, child1, child2
    replace parent1 with best1
    replace parent2 with best2

## Select down to size

This algorithm differs from the generic GA in that parents are selected uniformly at random with replacement instead of via tournament selection. Additionally, the population is selected down to size: at the end of each generation, the population of children for the next generation and the current generation's population are merged and tournament selection with replacement is used to select which individuals to pass forward to the next generation.

P <- generate a population of individuals randomly
P' <- ()
while stopping criterion has not been met:
    pop_size times do
        parent1, parent2 <- get two randomly selected individuals from the population P
        child1, child2 <- with probability cross_rate crossover parent1, parent2
        child1 <- mutate child1
        child2 <- mutate child2
        add child1 and child 2 to population P'

    while size(P'') < pop_size
        i <- tournament_selection(P + P')
        add i to P''

    elitism: if the best fitness individual is not in P'', replace the worst individual in P'' with this best one

    P <- P''
    P' <- ()
    P'' <- ()

## Lonely mutant

In this algorithm, a single individual is initialized randomly. Mutation is applied and whenever the mutant is superior to the original, the mutant replaces the original. No crossover occurs.

m <- generate one individual randomly
while stopping criterion has not been met:
    m' <- mutate m
    if fitness(m') > fitness(m)
        m <- m'

## Every man in an island

Each individual in this algorithm is like an island population of one. First, a population of individuals is generated randomly. Each individual is mutated and if the mutant is superior, it replaces the original. Each individual crosses over with its neighbor in a one-directional ring topology and if either child of crossover is superior to the original, the child replaces the original. This algorithm is similar to the PGA described in "Evolution in time and space", but with a directed-ring neighborhood arrangement so that each individual has only one neighbor.

P <- generate a population of individuals randomly
while stopping criterion has not been met:
    for i=0; i fitness(P[i])
            P[i] <- p
    for i=0; i fitness(P[i])
            P[i] <- child1
        if fitness(child2) > fitness(P[i])
            P[i] <- child2

## Hill climbing

This is a deterministic hill climbing algorithm. An individual is initialized randomly. While the individual is not at a local optimum, the algorithm takes a ``step" (increments or decrements one of its genes by the step size). If the resulting individual has better fitness, it replaces the original and the step size doubles. If the result is worse, the step size halves. Once a gene is at a local optimum (holding all other genes constant) then stepping begins again on the next gene. When the individual reaches a local optimum, a new solution is randomly generated and hill climbing begins again. The best prior solution is remembered. This algorithm is only intended for problems that take an integer or floating point array as input.

i <- generate an individual randomly
best_so_far <- i
while stopping criterion has not been met:
    get i's bit string and convert it to the problem representation (int or float)
    increment or decrement one of the genes by the step size
    if the resulting individual has higher fitness
        replace i with this individual and increase the step size
    else
        decrease the step size
    if the step size reaches zero and increments and decrements of the current gene have been tested
        move on to the next gene
    if i is at a local optimum
        if fitness(i) > fitness(best_so_far)
            best_so_far <- i

## King of the hill

This algorithm is identical to the hill climber except that once two solutions reach a local optimum, they begin to crossover with each other.

i <- generate an individual randomly
P <- ()
while stopping criterion has not been met:
    get i's bit string and convert it to the problem representation (int or float)
    increment or decrement one of the genes by the step size
    if the resulting individual has higher fitness
        replace i with this individual and increase the step size
    else
        decrease the step size
    if the step size reaches zero and increments and decrements of the current gene have been tested
        move on to the next gene
    if i is at a local optimum
        add i to P
        if there are individuals in P added by crossover that have not climbed their local hills
            i <- the next child of crossover that has not hill climbed
        else
            i <- generate an individual randomly
    if size(P) > 1
        parent1, parent2 <- get two random individuals from P
        child1, child2 <- crossover parent1, parent2
        if the fitness of child1 is greater than the fitness of the worse of the two parents
            add child1 to P
        if the fitness of child2 is greater than the fitness of the worse of the two parents
            add child2 to P
        i <- generate an individual randomly
